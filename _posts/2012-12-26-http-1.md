---
layout: post
title: "HTTP [1]"
date: 2012-12-26 14:29
comments: true
categories: [http]
---

### HTTP over TCP

#### How HTTP uses TCP connections?

1. The browser extracts the hostname
2. The browser looks up the IP address for this hostname (DNS)
3. The browser get the port number (80)
4. The browser makes a TCP connection to XX.XX.XX.XX port 80
5. The browser sends an HTTP GET request message to the server
6. The browser reads the HTTP response message from the server
7. The browser closes the connection

#### Delays, bottlenecks and clogs in TCP connections

+ Notice that the transaction processing time can be quite small compared to
the time required to set up TCP connections and transfer the request and 
response messages.

	1. DNS lookup delay
	2. Connection setup delay, occurring for every new TCP connection (TCP Slow
Start)
	3. Request message transfer delay
	4. Response message transfer delay

+ Most common TCP-related delays affecting HTTP programmers
	
	1. The TCP connection setup handshake
		
		When payload is small (usually condition), setup handshake become big.

	2. TCP slow-start congestion control
		
		Because of TCP slow-start feature, new connections are slower than 
	*"tuned"* connections. HTTP's open-transfer-close communication model is
	doomed to be slow. Fortunately we have HTTP *persistent connections*.

	3. Nagle's algorithm for data aggregation
	
		Nagle's algorithm attempts to bundle up a large amount of TCP data
	before sending a packet. But small HTTP messages may not fill a packet,
	so they me be delayed waiting additional data that will never arrive. 
	And Nagle's algorithm will hold up the sending of data until an 
	acknowledgment. but the acknowledgment itself will be delayed 100-200 ms
	by the daleyed acknowledgment algorithm.
		You can disable Nagle's algorithm by setting TCP_NODELAY parameter 
	of TCP protocol stack.

	4. TCP's delay acknowledgment algorithm for piggybacked acknowledgments

		TCP's piggybacking can make more efficient use of the 
	network, but HTTP's request-reply behavior reduces the chances that 
	piggybacking can occur.
	
	5. TIME_WAIT delays and port exhaustion

#### HTTP optimizations, including parallel, keep-alive, and pipelined connections
